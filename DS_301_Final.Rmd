---
title: "DS 301 Final"
author: "Michael Egle"
date: "4/26/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(tree)
library(stats)
library(factoextra)
library(neuralnet)
library(mltools)
library(data.table)
library(MASS)
```

```{r, include=FALSE}
cas <- read_csv("cas.csv") %>%
  janitor::clean_names()
accidents <- read_csv("dftRoadSafety_Accidents_2016.csv") %>%
  janitor::clean_names()
makemodel <- read_csv("MakeModel2016.csv") %>%
  janitor::clean_names()
veh <- read_csv("veh.csv") %>%
  janitor::clean_names()
```

## Data cleaning

```{r}
accidents <- accidents %>%
  mutate(weather_conditions = case_when(weather_conditions == -1 ~ "No data",
                                        weather_conditions == 1 ~ "Fine",
                                        weather_conditions == 2 ~ "Rain_no_high_wind",
                                        weather_conditions == 3 ~ "Snow_no_high_wind",
                                        weather_conditions == 4 ~ "Fine_high_wind",
                                        weather_conditions == 5 ~ "Rain_high_wind",
                                        weather_conditions == 6 ~ "Snow_high_wind",
                                        weather_conditions == 7 ~ "Fog_or_mist",
                                        weather_conditions == 8 ~ "Other",
                                        weather_conditions == 9 ~ "Unknown",
                                        TRUE ~ "NA"),
         accident_severity = case_when(accident_severity == 1 ~ "Fatal",
                                       accident_severity == 2 ~ "Serious",
                                       accident_severity == 3 ~ "Slight"),
         light_conditions = case_when(light_conditions == 1 ~ "Daylight",
                                      light_conditions == 4 ~ "Darkness_lights_lit",
                                      light_conditions == 5 ~ "Darkness_lights_unlit",
                                      light_conditions == 6 ~ "Darkness_no_lighting",
                                      light_conditions == 7 ~ "Unknown",
                                      light_conditions == -1 ~ "No data",
                                      TRUE ~ "NA"),
         road_surface_conditions = case_when(road_surface_conditions == 1 ~ "Dry",
                                      road_surface_conditions == 2 ~ "Wet_or_Damp",
                                      road_surface_conditions == 3 ~ "Snow",
                                      road_surface_conditions == 4 ~ "Frost_or_Ice",
                                      road_surface_conditions == 5 ~ "Flood_over_3cm",
                                      road_surface_conditions == 6 ~ "Oil_or_diesel",
                                      road_surface_conditions == 7 ~ "Mud",
                                      road_surface_conditions == -1 ~ "No data",
                                      TRUE ~ "NA")) %>%
  filter(weather_conditions != "No data" & weather_conditions != "Other" &
         weather_conditions != "Unknown" & weather_conditions != "NA" &
         light_conditions != "No data" & light_conditions != "Other" &
         light_conditions != "Unknown" & light_conditions != "NA" &
         road_surface_conditions != "No data" & road_surface_conditions != "Other" &
         road_surface_conditions != "Unknown" & road_surface_conditions != "NA") 
         # get rid of ambiguous/unknown weather/light conditions
```

# Question 1: Can We Predict The Severity of an Accident?

## EDA

```{r}
prop.table(table(accidents$accident_severity, accidents$weather_conditions), margin = 2)
```


It appears that the weather might not have a *huge* impact on accidents, but it's possible that it plays a role. We'll have to investiage further once we start modeling.

```{r}
prop.table(table(accidents$accident_severity, accidents$speed_limit), margin = 2)
```

It looks like there's a higher proportion of serious and fatal accidents on roads that have a speed limit of 60 km/h. This could be significant.

Let's try using an LDA model to classify the accident severity

```{r}
set.seed(37)

accidents <- accidents[complete.cases(accidents),]

test_index <- sample(1:nrow(accidents), nrow(accidents) / 2, replace = F)

train <- accidents[-test_index,]
test <- accidents[test_index,]

acc_lda <- lda(accident_severity ~ .-accident_index,
               data = train) # the index doesn't offer any predictive value
# The above line will take a while, be patient!


lda_test <- predict(acc_lda, test)

table(lda_test$class, test$accident_severity)
```

# Question 2: Can we predict when an accident will be fatal based on the driving conditions?

First, let's select columns that correspond to driving conditions. We have decided to go with Weather Conditions, Light Conditions and Road Surface Conditions for our predictors
```{r}
conditions <- accidents %>% 
  dplyr::select(
    accident_severity, 
    weather_conditions, 
    light_conditions, 
    road_surface_conditions)
```

Now, we must convert our response into a binary variable that is either "Fatal" or "Not Fatal"
```{r}
conditions <- conditions %>% dplyr::mutate(
    accident_severity = case_when(accident_severity != "Fatal" ~ "Not Fatal",
                                  accident_severity == "Fatal" ~ "Fatal")
  ) 
```

Finally, we need to convert all of the categorical variables into factors
```{r}
conditions <- conditions %>% 
  dplyr::mutate(
    accident_severity = as.factor(conditions$accident_severity), 
    weather_conditions = as.factor(conditions$weather_conditions), 
    light_conditions = as.factor(conditions$light_conditions), 
    road_surface_conditions = as.factor(conditions$road_surface_conditions))
```

Let's look at how balanced our data is
```{r}
conditions %>% group_by(accident_severity) %>% summarise(count=n())
```
Clearly the data is not as balanced as we would like. Only 1.24% of accidents are fatal, so that will need to be taken into consideration as we proceed

Now that we have our data all cleaned, we can separate it into training and testing sets
```{r}
set.seed(19)
test_idx = sample(1:nrow(conditions), nrow(conditions)/3)
train = conditions[-test_idx,]
test = conditions[test_idx,]
```

The first model we are going to try is binary logistic regression. We will fit the model using Accident Severity as the response, and all the other variables as our predictors.
```{r}
glm.fit <- glm(accident_severity ~ ., data = test, family = 'binomial')
glm.prob = predict(glm.fit,test,type='response') 
```

In order to pick a threshold value for our model, we need to plot the true positive rate v. false positive rate and true negative rate v. false negative rate. Since our dataset is so unbalanced, it is important to pick a value that ensures a nice tradeoff between the two errors since our model will most likely pick "Not Fatal" 100% of the time if we don't.
```{r}
ROCRpred = ROCR::prediction(glm.prob, test$accident_severity)
plot(ROCR::performance(ROCRpred,'tpr','fpr'),colorize=TRUE,print.cutoffs.at=seq(0.95,1,by=0.01), text.adj=c(-0.2,1.7))
plot(ROCR::performance(ROCRpred,'tnr','fnr'),colorize=TRUE,print.cutoffs.at=seq(0.95,1,by=0.01), text.adj=c(-0.2,1.7))
```

The plots show that 0.99 is a good middle ground to balance the two errors
```{r}
glm.pred = rep("Not Fatal", length(glm.prob))
glm.pred[glm.prob > 0.99] = "Fatal"
```

Let's now display the confusion matrix and overall accuracy to see how our model performs
```{r}
table(glm.pred, test$accident_severity)
mean(glm.pred == test$accident_severity)
```
So, our logistic model can predict when an accident will be fatal based on road conditions ~33% of the time. Not horrible given the lack of predictors and unbalanced data, but let's try some different models to see if we can reduce this error.

Let's try a tree model to see if it can fix this error
```{r}
tree.conditions = tree(accident_severity~.,data=train)
tree.pred = predict(tree.conditions, newdata=test, type="class")
table(tree.pred, test$accident_severity)
```
Again, since the data is so unbalanced, the tree predicts "Not Fatal" 100% of the time in order to achieve and accuracy of 98.68% which looks good, but does not fulfill our purpose.\
\
Let's try a neural network next.\
We first need to one-hot encode our data in order to pass it into the neural network. The reason we do this is because if we pass in each predictor as a factor, it will weigh higher values more which will hurt the accuracy of the model. By creating a variable for each factor level, they all get weighed evenly.
```{r}
train2 <- one_hot(data.table(train), cols=c("light_conditions", "weather_conditions", "road_surface_conditions"))
test2 <- one_hot(data.table(test), cols=c("light_conditions", "weather_conditions", "road_surface_conditions"))
```

Now, let's build and train the neural network. We will use a single hidden layer with 6 neurons and each neuron will use the logistic function as the activation function. This provides non-linearity to help map the abstract complexities and patterns found in the data.
```{r}
nn=neuralnet(accident_severity~.,data=train2, hidden=6,act.fct = "logistic", linear.output = FALSE)
```

Below, you can see what our neural network looks like
```{r}
plot(nn)
```

It's now time to run the network on the test data.
```{r}
Predict=compute(nn,test2)
head(Predict$net.result, 5)
```
We now have a table with each column representing an output neuron. The first column is the output of the "Not Fatal" output neuron, and the second column is the output of the "Fatal" output neuron.\
\
Before we label each of these predictions, we must choose a confidence value. Normally, a model should have output neurons that are really close to 1 or 0 depending on the output. However, due to our unbalanced data, we must choose a value that is closer to the 0.9 - 1 range like we did for logistic regression. Let's plot the true positive rate v. false positive rate and true negative rate v. false negative rate
```{r}
ROCRpred = ROCR::prediction(Predict$net.result[,2], test2$accident_severity)
plot(ROCR::performance(ROCRpred,'tpr','fpr'),colorize=TRUE,print.cutoffs.at=seq(0.95,1,by=0.01), text.adj=c(-0.2,1.7))
plot(ROCR::performance(ROCRpred,'tnr','fnr'),colorize=TRUE,print.cutoffs.at=seq(0.95,1,by=0.01), text.adj=c(-0.2,1.7))
```

A threshold value of 0.99 should work again.
```{r}
results <- seq(0,0,length.out=nrow(Predict$net.result))
for (i in 1:nrow(Predict$net.result)) {
  if (Predict$net.result[i,2] > 0.99) {
    results[i] <- "Fatal"
  } else {
    results[i] <- "Not Fatal"
  }
}
```

Let's look at the results.
```{r}
table(results, test2$accident_severity)
mean(results == test2$accident_severity)
```

The neural net gets 69.53% overall accuracy, and it gets 47.4% on fatal and 69.82% on not fatal.



